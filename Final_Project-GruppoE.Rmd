# Progetto Finale - Gruppo E
#### Giacomo Serafini, Enrico Guerriero, Leonardo Marsich, Gilberto Bran

## Data Set
Il dataset *WiscNursingHome* racchiude le informazioni riguardo diverse centinaia di case di riposo, informazioni che poi saranno utilizzate per capire come si relaziona il numero di pazienti rispetto alle caratteristiche della struttura.   
Nel dataset sono presenti 12 variabili:

* *hospID*: l'ID rappresentativo della singola struttura
* *CRYEAR*: il rapporto dei costi annuo
* *TPY*: il totale pazienti annui
* *NUMBED*: il numero di letti
* *SQRFOOT*: il numero di piedi quadrati della struttura
* *MSA*: codice dell'area statistica metropolitana (area divisa in 13 zone, più lo 0 se rurale)
* *URBAN*: 1 se urbana, O se rurale
* *PRO*: 0 se non-profit, 1 altrimenti
* *TAXEXEMPT*: 1 se esente dalle tasse
* *SELFFUNDINS*: 1 se autofinanziato per l'assicurazione
* *MCERT*: 1 se certificato Medicare
* *ORGSTR*: 1 se con finalità di lucro, 2 se esente dalle tasse, 3 se unità governativa

L'obiettivo della nostra analisi sarà quindi quello di capire come le varie caratteristiche di una casa di riposo sono tra loro collegate (se collegate in alcun modo), per poter così capire quali sono le principali peculiarità di una struttura che portano ad avere un numero maggiore di pazienti.

```{r include=FALSE}
# Richiamo delle librerie
library(corrplot)
library(ggplot2)
library(cowplot)
library(dplyr)
library(factoextra)
library(cluster)
library(grid)

# Creazione del dataset da WiscNursingHome
Data <- read.csv("WiscNursingHome.csv", header = TRUE)

# Fattorizzazione delle variabili categoriali
Data$CRYEAR <- factor(Data$CRYEAR)
Data$MSA <- factor(Data$MSA)
Data$URBAN <- factor(Data$URBAN)
Data$PRO <- factor(Data$PRO)
Data$TAXEXEMPT <- factor(Data$TAXEXEMPT)
Data$SELFFUNDINS <- factor(Data$SELFFUNDINS)
Data$MCERT <- factor(Data$MCERT)
Data$ORGSTR <- factor(Data$ORGSTR)

# Ci sono alcuni dati mancanti?
na.id.Data <- apply(is.na(Data), 2, which) 
# Abbiamo 10 dati mancanti in SQRFOOT
na.SQRFOOT <- na.id.Data$SQRFOOT
# Data frame senza NA
DataNa <- Data[-na.SQRFOOT,]
```

Visualizziamo il dataset:

```{r, include = T, echo = F}
summary(Data)
```

Nel dataset sono presenti solo 10 dati mancanti nella colonna SQRFOOT.


## Variabile Risposta

La variabile risposta individuata è la variabile TPY, ovvero il numero totale di pazienti ospitati nella casa di riposo in un anno.
Osserviamo in primo luogo la distribuzione di TPY:

```{r, include = T, echo = F}
summary(Data$TPY)
r1 <- ggplot(data = Data, aes(y = TPY)) +
  geom_boxplot(fill = "yellow") +
  theme_bw() +
  labs(y = "TPY") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.title = element_blank(),
        legend.text = element_text(size = 12),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank()) +
  xlim(-0.8,0.8) +
  geom_segment(data  = Data, aes(x = -0.375, xend = 0.375, y = mean(TPY), yend = mean(TPY)),
               linewidth = 1, linetype = "dashed") +
  xlab("")+
  geom_text(data = Data, aes(x = 0.4, y = mean(TPY), label = sprintf("Media")),
            hjust = 0, vjust = 0) +
  geom_text(data = Data, aes(x = 0.4, y = median(TPY) - 10,
                             label = sprintf("Mediana")),
            hjust = 0, vjust = 0)
r2 <- ggplot(data = Data, aes(x = TPY)) +
  geom_histogram(aes(y = after_stat(density)), col = "black", fill = "yellow", bins = 20) +
  geom_density(linewidth = 0.8, fill = "pink", alpha = 0.3) +
  theme_bw() +
  labs(y = "TPY", x = "") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.title = element_blank(),
        legend.text = element_text(size = 12),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank())
title <- ggdraw() + 
  draw_label(
    "Distribuzione di TPY",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    plot.margin = margin(0, 0, 0, 7)
  )
rowsplot <- plot_grid(r1, r2,
          nrow = 1)
plot_grid(title,
          rowsplot,
          ncol = 1,
          rel_heights = c(0.1, 1))
```

Si osserva un'assimetria destra nella distribuzione di TPY: la coda destra è molto lunga, come si vede da entrambi i grafici; inoltre, la media è superiore alla mediana.
Ci sono trasformazioni della variabile che possono renderla simmetrica, la migliore che è stata individuata è la trasformazione logaritmica:

```{r, include = T, echo = F}
summary(log(Data$TPY))
r1 <- ggplot(data = Data, aes(y = log(TPY))) +
  geom_boxplot(fill = "yellow") +
  theme_bw() +
  labs(y = "log(TPY)") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.title = element_blank(),
        legend.text = element_text(size = 12),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank()) +
  xlim(-0.8,0.8) +
  geom_segment(data  = Data, aes(x = -0.375, xend = 0.375,
                                 y = mean(log(TPY)), yend = mean(log(TPY))),
               linewidth = 1, linetype = "dashed") +
  xlab("")+
  geom_text(data = Data, aes(x = 0.4, y = mean(log(TPY)-0.1), label = sprintf("Media")),
            hjust = 0, vjust = 0) +
  geom_text(data = Data, aes(x = 0.4, y = median(log(TPY))+0.05,
                             label = sprintf("Mediana")),
            hjust = 0, vjust = 0)
r2 <- ggplot(data = Data, aes(x = log(TPY))) +
  geom_histogram(aes(y = after_stat(density)), col = "black", fill = "yellow", bins = 20) +
  geom_density(linewidth = 0.8, fill = "pink", alpha = 0.3) +
  theme_bw() +
  labs(y = "log(TPY)", x = "") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.title = element_blank(),
        legend.text = element_text(size = 12),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank())
title <- ggdraw() + 
  draw_label(
    "Distribuzione del logaritmo di TPY",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    plot.margin = margin(0, 0, 0, 7)
  )
rowsplot <- plot_grid(r1, r2,
          nrow = 1)
plot_grid(title,
          rowsplot,
          ncol = 1,
          rel_heights = c(0.1, 1))
```



## Variabili Quantitative

Iniziamo a vedere le variabili esplicative quantitative, quindi NUMBED e SQRFOOT.

```{r, include = T, echo = F}
"Summary NUMBED"
summary((Data$NUMBED))
"Summary SQRFOOT"
summary((Data$SQRFOOT))
c1 <- ggplot(data = Data, aes(y = NUMBED)) +
  geom_boxplot(fill = "yellow") +
  theme_bw() +
  labs(y = "NUMBED") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.title = element_blank(),
        legend.text = element_text(size = 12),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank()) +
  xlim(-0.8,0.8) +
  geom_segment(data  = Data, aes(x = -0.375, xend = 0.375, y = mean(NUMBED), yend = mean(NUMBED)),
               linewidth = 1, linetype = "dashed") +
  xlab("")+
  geom_text(data = Data, aes(x = 0.4, y = mean(NUMBED), label = sprintf("Media")),
            hjust = 0, vjust = 0) +
  geom_text(data = Data, aes(x = 0.4, y = median(NUMBED) - 25,
                             label = sprintf("Mediana")),
            hjust = 0, vjust = 0)
c2 <- ggplot(data = Data, aes(x = NUMBED)) +
  geom_histogram(aes(y = after_stat(density)), col = "black", fill = "yellow", bins = 20) +
  geom_density(linewidth = 0.8, fill = "pink", alpha = 0.3) +
  theme_bw() +
  labs(y = "NUMBED", x = "") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.title = element_blank(),
        legend.text = element_text(size = 12),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank())
c3 <- ggplot(data = DataNa, aes(y = SQRFOOT)) +
  geom_boxplot(fill = "yellow") +
  theme_bw() +
  labs(y = "SQRFOOT") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.title = element_blank(),
        legend.text = element_text(size = 12),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank()) +
  xlim(-0.8,0.8) +
  geom_segment(data  = DataNa, aes(x = -0.375, xend = 0.375, y = mean(SQRFOOT), yend = mean(SQRFOOT)),
               linewidth = 1, linetype = "dashed") +
  xlab("")+
  geom_text(data = DataNa, aes(x = 0.4, y = mean(SQRFOOT), label = sprintf("Media")),
            hjust = 0, vjust = 0) +
  geom_text(data = DataNa, aes(x = 0.4, y = median(SQRFOOT) - 10,
                             label = sprintf("Mediana")),
            hjust = 0, vjust = 0)
c4 <- ggplot(data = DataNa, aes(x = SQRFOOT)) +
  geom_histogram(aes(y = after_stat(density)), col = "black", fill = "yellow", bins = 20) +
  geom_density(linewidth = 0.8, fill = "pink", alpha = 0.3) +
  theme_bw() +
  labs(y = "SQRFOOT", x = "") +
  theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
        axis.title = element_text(size = 14),
        axis.text = element_text(size = 12),
        legend.title = element_blank(),
        legend.text = element_text(size = 12),
        axis.ticks.x = element_blank(),
        axis.text.x = element_blank())
title <- ggdraw() + 
  draw_label(
    "Distribuzione di NUMBED e SQRFOOT",
    fontface = 'bold',
    x = 0,
    hjust = 0
  ) +
  theme(
    plot.margin = margin(0, 0, 0, 7)
  )
rowsplot <- plot_grid(c1, c2,
                      c3, c4,
          nrow = 2)
plot_grid(title,
          rowsplot,
          ncol = 1,
          rel_heights = c(0.1, 2))
```

Si osserva una forte asimmetricità analoga a TPY anche nelle distribuzioni delle variabili esplicative, in particolare in SQRFOOT.

Analizziamo ora le correlazioni tra le variabili quantitative (compresa la risposta)

```{r echo=FALSE}
plot <- ggplot() +
  theme_void()
riquadro <- rectGrob(gp = gpar(fill = "white", col = "black"))
plot <- plot + annotation_custom(riquadro, xmin = 0, xmax = 1, ymin = 0, ymax = 1)
title1 <- plot + annotation_custom(ggplotGrob(
  ggdraw() +
    draw_label(
      "TPY",
      fontface = 'bold',
      x = 0.5,
      y = 0.5,
      hjust = 0.5,
      vjust = 0.5,
      size = 20
    )
), xmin = 0, xmax = 1, ymin = 0, ymax = 1)
title2 <- plot + annotation_custom(ggplotGrob(
  ggdraw() +
    draw_label(
      "NUMBED",
      fontface = 'bold',
      x = 0.5,
      y = 0.5,
      hjust = 0.5,
      vjust = 0.5,
      size = 20
    )
), xmin = 0, xmax = 1, ymin = 0, ymax = 1)
title3 <- plot + annotation_custom(ggplotGrob(
  ggdraw() +
    draw_label(
      "SQRFOOT",
      fontface = 'bold',
      x = 0.5,
      y = 0.5,
      hjust = 0.5,
      vjust = 0.5,
      size = 20
    )
), xmin = 0, xmax = 1, ymin = 0, ymax = 1)
cor1 <- plot + annotation_custom(ggplotGrob(
  ggdraw() +
    draw_label(
    round(cor(Data$TPY, Data$NUMBED), digits = 3),
      fontface = 'bold',
      x = 0.5,
      y = 0.5,
      hjust = 0.5,
      vjust = 0.5,
      size = 20,
    color = "red"
    )
), xmin = 0, xmax = 1, ymin = 0, ymax = 1)
cor2 <- plot + annotation_custom(ggplotGrob(
  ggdraw() +
    draw_label(
    round(cor(DataNa$TPY, DataNa$SQRFOOT), digits = 3),
      fontface = 'bold',
      x = 0.5,
      y = 0.5,
      hjust = 0.5,
      vjust = 0.5,
      size = 20,
    color = "red"
    )
), xmin = 0, xmax = 1, ymin = 0, ymax = 1)
cor3 <- plot + annotation_custom(ggplotGrob(
  ggdraw() +
    draw_label(
    round(cor(DataNa$NUMBED, DataNa$SQRFOOT), digits = 3),
      fontface = 'bold',
      x = 0.5,
      y = 0.5,
      hjust = 0.5,
      vjust = 0.5,
      size = 20,
    color = "red"
    )
), xmin = 0, xmax = 1, ymin = 0, ymax = 1)
sc1 <- plot + annotation_custom(ggplotGrob(
  ggplot(data = Data, aes(x = NUMBED, y = TPY)) +
   geom_point(shape=1) +
   theme_void() +
   xlab("") +
   ylab("") +
   geom_smooth(se = F, method = 'loess', formula = 'y ~ x', lwd = 0.75, col = "red") +
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())), xmin = 0, xmax = 1, ymin = 0, ymax = 1)
sc2 <- plot + annotation_custom(ggplotGrob(
  ggplot(data = DataNa, aes(x = SQRFOOT, y = TPY)) +
   geom_point(shape=1) +
   theme_void() +
   xlab("") +
   ylab("") +
   geom_smooth(se = F, method = 'loess', formula = 'y ~ x', lwd = 0.75, col = "red") +
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())), xmin = 0, xmax = 1, ymin = 0, ymax = 1)
sc3 <- plot + annotation_custom(ggplotGrob(
  ggplot(data = DataNa, aes(x = SQRFOOT, y = NUMBED)) +
   geom_point(shape=1) +
   theme_void() +
   xlab("") +
   ylab("") +
   geom_smooth(se = F, method = 'loess', formula = 'y ~ x', lwd = 0.75, col = "red") +
  theme(axis.ticks.x = element_blank(),
        axis.text.x = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())), xmin = 0, xmax = 1, ymin = 0, ymax = 1)
plot_grid(title1, sc1, sc2,
          cor1, title2, sc3,
          cor2, cor3, title3,
          nrow = 3)
```

Si può subito vedere come ci sia una correlazione quasi totale tra il *TPY* (totale patienti annui) e il *NUMBED* (numero di letti). Inoltre, si può osservare anche un'alta correlazione positiva tra il totale pazienti annui e i piedi quadrati della struttura (*SQRFOOT*), così come tra i piedi quadrati della struttura e il numero di letti. Ciò suggerisce che tutte queste variabili possano essere legate tra loro da una relazione lineare.


## Variabili Categoriche

Ora segue anche una breve analisi delle variabili categoriche, in primo luogo delle loro distribuzioni di frequenza.

```{r echo=FALSE}
p1 <- ggplot(data = Data, aes(x = CRYEAR, fill = CRYEAR)) +
  geom_bar(col = "black")+
  scale_fill_manual(values = heat.colors(2)) +
  theme_classic() +
  theme(legend.position = "none") +
  ylab("")

p2 <- ggplot(Data[Data$MSA != 0,], aes(x=MSA, fill=MSA)) +
  geom_bar(col = "black")+
  scale_fill_manual(values = heat.colors(13)) + 
  theme_classic() +
  theme(legend.position = "") +
  ylab("")

p3 <- ggplot(data = Data, aes(x = URBAN, fill = URBAN)) +
  geom_bar(col = "black")+
  scale_fill_manual(values = heat.colors(2)) +
  theme_classic() + 
  theme(legend.position = "none") +
  ylab("")

p4 <- ggplot(data = Data, aes(x = PRO, fill = PRO)) +
  geom_bar(col = "black")+
  scale_fill_manual(values = heat.colors(2)) +
  theme_classic() + 
  theme(legend.position = "none") +
  ylab("")

p5 <- ggplot(data = Data, aes(x = TAXEXEMPT, fill = TAXEXEMPT)) +
  geom_bar(col = "black")+
  scale_fill_manual(values = heat.colors(2)) +
  theme_classic() + 
  theme(legend.position = "none") +
  ylab("")

p6 <- ggplot(data = Data, aes(x = SELFFUNDINS, fill = SELFFUNDINS)) +
  geom_bar(col = "black")+
  scale_fill_manual(values = heat.colors(2)) +
  theme_classic() + 
  theme(legend.position = "none") +
  ylab("")

p7 <- ggplot(data = Data, aes(x = MCERT, fill = MCERT)) +
  geom_bar(col = "black")+
  scale_fill_manual(values = heat.colors(2)) +
  theme_classic() +
  theme(legend.position = "none") +
  ylab("")

p8 <- ggplot(data = Data, aes(x = ORGSTR, fill = ORGSTR)) +
  geom_bar(col = "black")+
  scale_fill_manual(values = heat.colors(3)) +
  theme_classic() +  
  theme(legend.position = "none") +
  ylab("")


# Grafico di tutti i grafici delle variabili categoriali
plot_grid(p1,p2,p3,p4,
          p5,p6,p7,p8,
          nrow = 2)
```

Abbiamo deciso per quanto riguarda la variabile *MSA* di non includere graficamente le osservazioni appartenenti alla classe "0", ovvero le case di riposo poste in zone rurali, poiché già rappresentate nella variabile *URBAN*.


Andiamo anche a studiare velocemente le distribuzioni condizionate della variabile risposta:    

```{r echo=FALSE}
c4 <- ggplot(data = Data, aes(x = CRYEAR, y = TPY, fill = CRYEAR)) +
  geom_boxplot() +
  scale_fill_manual(values = heat.colors(2)) +
  theme_classic() +
  theme(legend.position = "")

c5 <- ggplot(data = Data, aes(x = URBAN, y = TPY, fill = URBAN)) +
  geom_boxplot() +
  theme_classic() +
  theme(legend.position = "")+
  scale_fill_manual(values = heat.colors(2))

c6 <- ggplot(data = Data, aes(x = PRO, y = TPY, fill = PRO)) +
  geom_boxplot() +
  theme_classic() +
  theme(legend.position = "")+
  scale_fill_manual(values = heat.colors(2))

c7 <- ggplot(data = Data, aes(x = ORGSTR, y = TPY, fill = ORGSTR)) +
  geom_boxplot() +
  theme_classic() +
  theme(legend.position = "")+
  scale_fill_manual(values = heat.colors(3))

c8 <- ggplot(data = Data, aes(x = TAXEXEMPT, y = TPY, fill = TAXEXEMPT)) +
  geom_boxplot() +
  theme_classic() +
  theme(legend.position = "")+
  scale_fill_manual(values = heat.colors(2))

c9 <- ggplot(data = Data, aes(x = SELFFUNDINS, y = TPY, fill = SELFFUNDINS)) +
  geom_boxplot() +
  theme_classic() +
  theme(legend.position = "")+
  scale_fill_manual(values = heat.colors(2))

c10 <- ggplot(data = Data, aes(x = MCERT, y = TPY, fill = MCERT)) +
  geom_boxplot() +
  theme_classic() +
  theme(legend.position = "")+
  scale_fill_manual(values = heat.colors(2))

c11 <- ggplot(data = Data, aes(x = MSA, y = TPY, fill = MSA)) +
  geom_boxplot() +
  theme_classic() +
  theme(legend.position = "")+
  scale_fill_manual(values = heat.colors(14))

plot_grid(c4, c5, c6, c7,
          c8, c9, c10, c11,
          nrow = 2)
```

```{r include=FALSE}
resiplot <- function(fit, p) {
  #p è il primo grafico in alto a sinistra, così non c'è il rischio che gli si passi un p a caso
  
  # sopprimo il seguente output temporaneamente

  #per capire che data set utilizzare
  if(length(fitted.values(fit)) == 717){
    d = Data
    #print("resi plot utilizzando Data")
  }
  if(length(fitted.values(fit)) == 707){
    d = DataNa
    #print("resi plot utilizzando DataNa")
  }
  
  f <- ggplot(data = d, aes(x = fitted.values(fit), y = resid(fit))) +
    geom_point(shape=1) +
    theme_bw() +
    xlab("Valori fittati") +
    ylab("Residui") +
    geom_hline(yintercept = 0, col = "black", lty = 2) +
    geom_smooth(se = F, method = 'loess', formula = 'y ~ x', lwd = 0.75, col = "red")
  f1 <- ggplot(data = d, mapping = aes(resid(fit))) +
    geom_histogram(aes(y =after_stat(density)),bins = 20, col = "black", fill = "yellow", alpha = 1) + 
    geom_density(linewidth = 0.8, fill = "pink", alpha = 0.3) +
    theme_bw() +
    xlab("Residui") +
    ylab("Densità")
  f2 <- ggplot(data.frame(resid = rstandard(fit)),aes(sample = resid)) + 
    stat_qq(shape=1) +
    stat_qq_line(color = "red", linewidth = 1) +
    theme_bw() +
    xlab("Quantili teorici normale") +
    ylab("Quantili empirici")

  plot_grid(p, f,
            f1, f2,
            nrow = 2)
}
```

## Regressioni Lineari Semplici per la Stima di TPY

I due modelli di regressione semplice sono con le variabili NUMBED e SQRFOOT, in quanto si tratta delle uniche variabili quantitative del dataset.

#### Costruzione del Modello TPY ~ NUMBED

```{r echo=FALSE}
fit_NUMBED <- lm(TPY ~ NUMBED, data = Data)
summary(fit_NUMBED)
```

Studiando i valori ritornati dal summary, si può subito vedere come questo modello sia ottimo: per quanto riguarda i residui, la mediana è molto vicina allo zero, il primo e il terzo quartile sono disposti abbastanza simmetricamente rispetto lo zero, con minimo e massimo invece non si può fare lo stesso discorso e sono molto lontani dai quartili della distribuzione.     
Nel summary possiamo poi individuare l'intercetta e il coefficiente angolare: l'intercetta vale -0.8778 (valore vicino allo zero, il che ha senso perché nel caso di 0 letti ci si aspetta un numero di pazienti vicino allo zero) mentre il coefficiente angolare è uguale a 0.9272 (valore vicino all'1, infatti per ogni posto letto in più ci si aspetta un paziente in più).
Sull'intercetta si può fare un'ulteriore considerazione: lo standard error è 0.6925, quasi quanto l'intercetta; risulta infatti, dal test del t-value, che l'ipotesi nulla che il coefficiente sia nullo non può essere rifiutata.
Infine, studiando la statistica $R^2$, possiamo vedere un valore pari a 0.9678, il quale suggerisce un'aderenza del modello ai dati molto alta, quasi totale, circa del 97%.

Ora proviamo a costruire il modello senza intercetta, così da stabilire se possa essere migliore

```{r, echo=FALSE}
fit_NUMBED <- lm(TPY ~ NUMBED -1, data = Data)
summary(fit_NUMBED)
```

Il modello sembra essere migliorato, considerando che il coefficiente dell'$R^2$ è salito al 99.29%.
Dal momento che risulta plausibile e sensato che una casa di riposo con 0 posti letto ospiti 0 pazienti, accettiamo questo modello senza intercetta.
$$TPY = 0.920075\times NUMBED$$
Rappresentiamo graficamente la regressione e i suoi residui, così da poterli analizzare:

```{r echo=FALSE}
p <- ggplot(data = Data, aes(x = NUMBED, y = TPY)) +
   geom_point(shape=1) +
   theme_bw() +
   xlab("NUMBED") +
   ylab("TPY") +
   geom_smooth(se = F, method = 'lm', formula = 'y ~ x', lwd = 0.75, col = "red") +
  geom_point(aes(x = Data[564,'NUMBED'], y = Data[564,'TPY']), colour = "red", size = 1)
resiplot(fit_NUMBED, p)
```

Dallo scatterplot dato dalla relazione tra *TPY* come variabile risposta e *NUMBED* come variabile esplicativa, si vede subito come sia presente una relazione lineare tra le due
Analizzando i grafici, dal primo dei Residuals vs Fitted si può notare come, nonostante siano presenti degli outliers al di sotto della curva di regressione, i residui si dispongono in maniera per lo più simmetrica, suggerendo la linearità del modello.
Anche l'omoschedasticità sembra essere soddisfatta, a meno di una varianza leggermente minore per gli ospedali con meno persone, ma poi sembra stabilizzarsi.
Gli altri due grafici, invece, non ci permettono di affermare lo stesso per quanto riguarda la gaussianità; infatti le code sono molto più pesanti di una normale, specialmente la coda inferiore.
Tuttavia il modello è comunque più che accettabile, nonostante la non-normalità dei residui.
Eventuali trasformazioni per rendere i residui gaussiani rendono il modello maggiormente eteroschedastico, quindi le rifiutiamo a favore di un modello più omoschedastico e facile da interpretare.


#### Costruzione del Modello TPY ~ SQRFOOT

Analizziamo ora il secondo modello con SQRFOOT come variabile esplicativa.
```{r echo=FALSE}
fit_SQRFOOT <- lm(TPY ~ SQRFOOT, data = Data)
summary(fit_SQRFOOT)
```

Studiando i residui dal summary, si può vedere questi si dispongano simmetricamente rispetto lo zero, nonostante fra il minimo ed il massimo ci sia una differenza di 240, molto maggiore rispetto al range interquartilico e alla distanza riscontrata nel modello *TPY* ~ *NUMBED*.
La mediana si dispone comunque vicino allo 0, ed il primo ed il terzo quartile valgono rispettivamente -15.391 e 15.615, oltre ad essere assolutamente simmetrici, ci dicono anche che la metà dei valori si troverà proprio in questo intervallo.    
In questo modello l'intercetta vale 33.5475 mentre il coefficiente angolare è pari a 1.1179 (molto vicino a 1, quindi circa per ogni piede quadrato c'è un paziente in più). 
Infine, l'R^2 risulta pari a 0.6756, quindi abbiamo un'aderenza del modello di circa il 68%, quindi di nuovo alta nonostante minore rispetto a quella del modello precedente.
La retta di regressione lineare risulta essere:
$$TPY = 33.54754 + 1.11786 \times SQRFOOT$$
Questo modello risulta comunque peggiore di quello con *NUMBED*.
C'è però da considerare che, nel caso di *SQRFOOT*, il modello migliora qualora si effettui una trasformazione logaritmica della variabile risposta e della variabile esplicativa, ma verrà ripreso in seguito.


### Regressione Lineare Multipla con Variabili Categoriche    

Per costruire un modello di regressione multipla abbiamo provato ad aggiungere una variabile qualitativa ai modelli ottenuti precedentemente; non è stato preso in considerazione il modello che tiene conto sia di *NUMBED* sia di *SQRFOOT*, poiché le due variabili sono fortemente correlate e potrebbero generare effetti di multicollinearità.

Il primo modello proposto, con *NUMBED*, non è significativamente migliorabile con l'aggiunta di variabili categoriche, poiché la varianza dei dati è già spiegata molto bene e le nuove variabili risultano poco significative lasciando pressoché invariato l'$R^2$.

Procediamo quindi con la costruzione di un modello di regressione multipla introducendo una nuova variabile nel modello con *SQRFOOT*; in particolare, utilizzeremo il modello che considera le trasformazioni logaritmiche di *TPY* e *SQRFOOT*.

Per quanto riguarda le variabili dicotomiche, i due modelli migliori sono quelli individuati con l'introduzione delle variabili *PRO* e *TAXEXEMPT*:

```{r echo=FALSE}
fit_SQR_PRO <- lm(log(TPY) ~ log(SQRFOOT)*PRO, Data)
summary(fit_SQR_PRO)
fit_SQR_TAX <- lm(log(TPY) ~ log(SQRFOOT)*TAXEXEMPT, Data)
summary(fit_SQR_TAX)
```

Anche graficamente sembrano funzionare:

* Modello con PRO

```{r echo=FALSE}
p <- ggplot(data = DataNa, aes(x = log(SQRFOOT), y = log(TPY), col = PRO)) +
  geom_point(show.legend = F, alpha = 0.8, shape = 1) +
  theme_bw() +
  xlab("Log(SQRFOOT)") +
  ylab("Log(TPY)") +
  geom_smooth(data = DataNa[DataNa$PRO == 0,], se = F, method = 'lm', formula = 'y ~ x', lwd = 1, col = "salmon")+
  geom_smooth(data = DataNa[DataNa$PRO == 1,], se = F, method = 'lm', formula = 'y ~ x', lwd = 1, col = "darkgoldenrod1") +
  scale_color_manual(values = c("salmon", "darkgoldenrod1"))
resiplot(fit_SQR_PRO, p)
```

* Modello con TAXEXEMPT

```{r echo=FALSE}
p <- ggplot(data = DataNa, aes(x = log(SQRFOOT), y = log(TPY), col = TAXEXEMPT)) +
  geom_point(show.legend = F, alpha = 0.8, shape = 1) +
  theme_bw() +
  xlab("Log(SQRFOOT)") +
  ylab("Log(TPY)") +
  geom_smooth(data = DataNa[DataNa$TAXEXEMPT == 0,], se = F, method = 'lm', formula = 'y ~ x', lwd = 0.75, col = "salmon")+
  geom_smooth(data = DataNa[DataNa$TAXEXEMPT == 1,], se = F, method = 'lm', formula = 'y ~ x', lwd = 0.75, col = "goldenrod1") +
  scale_color_manual(values = c("salmon", "darkgoldenrod1"))
resiplot(fit_SQR_TAX, p)
```

Si osserva come entrambe le versioni siano molto valide, sembra quindi immediato pensare che il modello con la variabile ORGSTR sia ancora più valido, in quanto *ORGSTR* "unione" di *PRO* e *TAXEXEMPT* (vale 1 se "profit", 2 se "tax exempt" e 3 se "governmental unit"); tuttavia, risulta invece non significativa la differenza tra profit e governmental unit, sia per quanto riguarda l'intercetta sia per quanto riguarda l'interazione moltiplicativa.

Per maggiore significatività dei coefficienti e leggera superiorità in $R^2$ si sceglie quindi come preferibile il modello con la variabile categorica *PRO*.


## Train Set e Test Set

Per verificare la bontà dei due modelli individuati, si divide il dataset in due sottoinsiemi (casuali) composti l'uno dall'90% (Train Set) dei dati, l'altro dal restante 10% (Test Set).
La verifica avviene costruendo i due modelli che abbiamo ricavato sfruttando le osservazioni del Train Set, e poi utilizzarle per stimare le osservazioni nel Test Set.

### Modello regressione semplice TPY ~ NUMBED - 1

```{r echo=FALSE}
set.seed(69)

#Divisione data set
# 80% dei dati nel training e 20% nel test
sample <- sample(c(TRUE, FALSE), nrow(Data), replace=TRUE, prob=c(0.9,0.1))
train  <- Data[sample, ]
test   <- Data[!sample, ]

#Faccio il fit con il modello che abbiamo selezionato (che in caso si può cambiare)
fit_train <- lm(TPY ~ NUMBED - 1, train)
summary(fit_train)
```
Guardando il summary del modello applicato solo ad una parte dei dati si ritrova un risultato molto simile


```{r echo=FALSE}
#Dati predetti
pred <- predict.lm(fit_train, test)

dp <- ggplot()+
  geom_point(aes(x = test[,'TPY'], y = pred)) +
  ggtitle("Dati predetti vs dati reali") +
  geom_abline(intercept = 0, slope = 1, col = "red") +
  xlab("TPY reali") +
  ylab("TPY predetti")+
  theme_bw()

#calcolo residui
err <- abs(test[,'TPY'] - pred)
err <- err / abs(test[,'TPY'])
gr <- ggplot(data = test, aes(x = NUMBED, y = err)) +
  geom_point() +
  geom_abline(intercept = 0, slope = 0) +
  ggtitle("Grafico degli errori relativi") +
  xlab("Posti letto")+
  ylab("errore relativo")+
  scale_y_continuous(breaks = scales::pretty_breaks(n = 15))+
  theme_bw()

plot_grid(dp, gr)

```
Nel primo gafico confrontiamo i dati predetti rispetto ai dati reali del dataset test. Come si vede si avvicinano molto alla bisettrice del primo quadrante in rosso, ciò significa che i dati predetti si assomigliano molto ai dati reali.
Nel secondo grafico sono rappresentati gli errori relativi, e come si vede che la maggior parte degli errori sono ,molto piccoli.

Formula errore relativo
$$ err_{rel} = \frac{|x_{vero} - x_{pred}|}{|x_{vero}|}$$

```{r echo=FALSE}
summary(err)
```
Per essere più precisi il 75% dei dati ha un errore più piccolo del 6%, sfortunatamente l'errore più grande è del 42%.

### Modello MULTIVARIATO log(TPY) ~ log(SQRFOOT) * PRO
Facciamo adesso lo stesso studio con il secondo modello

```{r echo=FALSE}
set.seed(69)

#Divisione data set
# 90% dei dati nel training e 10% nel test
sample <- sample(c(TRUE, FALSE), nrow(DataNa), replace=TRUE, prob=c(0.9,0.1))
train  <- DataNa[sample, ]
test   <- DataNa[!sample, ]

#Faccio il fit con il modello che abbiamo selezionato (che in caso si può cambiare)
fit_train <- lm(log(TPY) ~ log(SQRFOOT) * PRO, train)
summary(fit_train)
```
Guardando il summary del modello applicato solo ad una parte dei dati si ritrovno di nuovo coefficienti molto simili a quelli gia ottenuti

```{r echo=FALSE}
#Dati predetti
pred <- predict.lm(fit_train, test)

dp <- ggplot()+
  geom_point(aes(x = test[,'TPY'], y = exp(pred))) +
  ggtitle("Dati predetti vs dati reali") +
  geom_abline(intercept = 0, slope = 1, col = "red") +
  xlab("TPY reali") +
  ylab("TPY predetti")+
  theme_bw()

#calcolo residui
err <- abs(test[,'TPY'] - exp(pred))
err <- err / abs(test[,'TPY'])
gr <- ggplot(data = test, aes(x = SQRFOOT, y = err)) +
  geom_abline(intercept = 0, slope = 0, col = "gray40") +
  geom_point() +
  ggtitle("Grafico degli errori relativi") +
  xlab("Piedi quadrati")+
  ylab("errore relativo")+
  scale_y_continuous(breaks = scales::pretty_breaks(n = 10))+
  theme_bw()

plot_grid(dp, gr)

```
Nel primo gafico confrontiamo i dati predetti rispetto ai dati reali del dataset test. Rispetto al modello precedente si osserva una maggiore dispersione.
Nel secondo grafico sono rappresentati gli errori relativi che come si poteva dedurre sono più alti

```{r echo=FALSE}
summary(err)
```
Per essere più precisi solo il 25% dei dati ha un errore minore del 5%. La metà dei dati ha un errore del 15%. e abbiamo errori che arrivano fino al 170%.

Se andiamo a ricordare il nostro modello considerando tutti i dati ricordiamo che la precentuale di dati spiegati è 68.96%.
```{r echo=FALSE}
quantile(err, 0.6896)
```
E l'errore relativo a quel quantile è del 23%. Quindi concludiamo che l'errore relativo della nostra predizione sulla percentuale di dati che il nostro modello prometteva di spiegare è al massimo del 23%.

### Esecuzione ripetuta del proceso train-test
La divisione del data-set fra quello di train e di test è casuale, quindi per controllare che non siamo stati fortunati nel caso che abbiamo studiato andremo a ripetere il processo 100 volte ed analizzare i risultati attraverso l'R^2 la varianza sui residui e l'errore relativo sui residui.

#### regressione semplice TPY ~ NUMBED - 1

```{r echo=False, warning=FALSE}
#Facciamo un ciclo for nel quale separiamo più volte il data set in test e train
#Numero di ripetizioni
niter <- 100
#prime due righe due modi diversi per calcolare l'r^2
r <- matrix(data = 0, nrow = 2, ncol = niter)
#Martice prima riga varianza dei residui seconda riga la media dell'errore relativo
e <- matrix(data = 0, nrow = 2, ncol = niter)
for (i in 1:niter){
  #Divido il dataset
  sample <- sample(c(TRUE, FALSE), nrow(Data), replace=TRUE, prob=c(0.9,0.1))
  train  <- Data[sample, ]
  test   <- Data[!sample, ]
  
  #Faccio il modello
  fit_train <- lm(TPY ~ NUMBED - 1, train)
  
  #Predizion
  pred <- predict.lm(fit_train, test)
  
  #calcolo residui
  res <- test[,'TPY'] - pred
  #media dati
  m <- mean(test[,'TPY'])
  # Residui totali
  sst <- sum((test[,'TPY'] - m)^2)
  #calcolo devianza dei residui
  sse <- sum(res^2)
  #devianza della regression
  ssr <- sum((pred - m)^2)
  
  #Calcolo dell'r quadro
  r1 <- (ssr / sst)
  r2 <- (1 - sse / sst)
  r[1, i] <-  r1
  r[2, i] <-  r2
  
  #salvo i residui
  e[1, i] <- sse / length(res)
  e[2, i] <- mean(abs(res) / abs(test[,'TPY']))
}
```

```{r echo=False}
#Distribuzioni degli r quadri calcolati
#Questa formula non funziona
r21 <- ggplot(data = NULL, aes(y = r[1,])) +
  geom_boxplot() +
  ylab("R^2")+
  scale_y_continuous(breaks = scales::pretty_breaks(n = 12, bounds = FALSE))+
  theme_bw()

r22 <- ggplot(data = NULL, aes(x = r[2,])) +
  geom_boxplot() +
  xlab("R^2")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 12, bounds = FALSE))+
  theme_bw()

r22
```


Per calcolare R^2 abbiamo usato la seguente formula
$$R^2 = 1 - \frac{dev_{res}} {dev_{tot}}$$
Come si può notare dal gradico la maggior parte dei dati si avvicina all'R^2 calcolato nel modello che considera la completezza dei dati, ovvero: 0.9929

```{r echo=FALSE}
rd <- ggplot(data = NULL, aes(e[1,])) +
  geom_boxplot()+
  ggtitle("Distribuzione varianze dei residui")+
  theme_bw()+
  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(), axis.title = element_blank())+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 12, bounds = FALSE))
  

rer <- ggplot(data = NULL, aes(x = e[2,]))+
  geom_boxplot() +
  ggtitle("Distibuzione media errori relativi")+
  theme_bw()+
  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(), axis.title = element_blank())+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 7, bounds = FALSE))

plot_grid(rd, rer)
```
Dal grafico si può notare che in media gli errori relativi sono molto piccoli, quasi tutti più piccoli del 10%.
(((Non so bene valutare la varianza dei residui)))


#### secondo modello

```{r}
#Facciamo un ciclo for nel quale separiamo più volte il data set in test e train
#Numero di ripetizioni
niter <- 100
#prime due righe due modi diversi per calcolare l'r^2
r <- matrix(data = 0, nrow = 2, ncol = niter)
#Martice prima riga varianza dei residui seconda riga la media dell'errore relativo
e <- matrix(data = 0, nrow = 2, ncol = niter)
for (i in 1:niter){
  #Divido il dataset
  sample <- sample(c(TRUE, FALSE), nrow(DataNa), replace=TRUE, prob=c(0.9,0.1))
  train  <- DataNa[sample, ]
  test   <- DataNa[!sample, ]
  
  #Faccio il modello
  fit_train <- lm(log(TPY) ~ log(SQRFOOT)*PRO, train)
  
  #Predizion
  pred <- predict.lm(fit_train, test)
  
  #calcolo residui
  res <- test[,'TPY'] - exp(pred)
  #media dati
  m <- mean(test[,'TPY'])
  # Residui totali
  sst <- sum((test[,'TPY'] - m)^2)
  #calcolo devianza dei residui
  sse <- sum(res^2)
  #devianza della regression
  ssr <- sum((exp(pred) - m)^2)
  
  #Calcolo dell'r quadro
  r1 <- (ssr / sst)
  r2 <- (1 - sse / sst)
  r[1, i] <-  r1
  r[2, i] <-  r2
  
  #salvo i residui
  e[1, i] <- sse / length(res)
  e[2, i] <- mean(abs(res) / abs(test[,'TPY']))
}


```


```{r echo = FALSE, warning=FALSE}
#Distribuzioni degli r quadri calcolati
r21 <- ggplot(data = NULL, aes(y = r[1,])) +
  geom_boxplot() +
  ylim(c(0.5,1))+
  ylab("R^2")+
  theme_bw()

r22 <- ggplot(data = NULL, aes(x = r[2,])) +
  geom_boxplot() +
  xlab("R^2")+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 12, bounds = FALSE))+
  theme_bw()


r22
```

Ricordiamo che l'R^2 ottenuto in precedenza è 0.6896, e possiamo andare a notare che la nostra distribuzione si avvicina molto a quel valore.

```{r echo=FALSE}
rd <- ggplot(data = NULL, aes(e[1,])) +
  geom_boxplot()+
  ggtitle("Distribuzione varianze dei residui")+
  theme_bw()+
  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(), axis.title = element_blank())
  

rer <- ggplot(data = NULL, aes(x = e[2,]))+
  geom_boxplot() +
  ggtitle("Distibuzione media errori relativi")+
  theme_bw()+
  theme(axis.ticks.y = element_blank(), axis.text.y = element_blank(), axis.title = element_blank())+
  scale_x_continuous(breaks = scales::pretty_breaks(n = 9, bounds = FALSE))

plot_grid(rd, rer)
```
Come abbiamo notato anche prima l'errore relativo in questo modello è più alto rispetto al primo ma osserviamo che le medie superano difficilmente il 0.28 

Dopo entrambe le analisi possiamo concludere che entrambi i modelli performano bene nel processo di train-test e i due casi specifici che siamo siamo andati a studiare non erano dei casi estremi.

## Clustering

In ultimo proviamo a creare dei raggruppamenti di osservazioni nel dataset che siano omogenei secondo un determinato criterio.
Il criterio selezionato è quello che ci sembra essere il più intuitivo: la dimensione della casa di riposo.
Infatti è possibile sfruttare le variabili NUMBED e SQRFOOT per definire una dimensione della casa di riposo, sia a livello di capacità sia a livello di superficie effettiva.
La variabile TPY sarà inclusa in ogni raggruppamento.
Il primo confronto che viene effettuato è tra la divisione ottenuta utilizzando solo 1 delle due variabili o entrambe.
Utilizzando il metodo delle k-medie e la distanza euclidea per il calcolo della matrice delle distanza, adottando 2 centri, otteniamo i seguenti risultati:

```{r echo = F}

# Costruisco le distanze (euclidee per variabili quantitative)
dist.numbed <- daisy(scale(Data[,c("NUMBED", "TPY")]))
#as.matrix(dist.numbed)[1:5,1:5] #matrice delle distanze
dist.sqrfoot <- daisy(scale(Data[,c("SQRFOOT", "TPY")]))
#as.matrix(dist.sqrfoot)[1:5,1:5] #matrice delle distanze
# NB la funzione scale serve a standardizzare il dataset

# Provo anche con la distanza rispetto a tutte e 3 le variabili
dist.quant <- daisy(scale(DataNa[,c("NUMBED", "SQRFOOT", "TPY")]))
#as.matrix(dist.quant)[1:5,1:5] #matrice delle distanze

# Provo il clustering con il metodo delle k medie
km.numbed <- kmeans(scale(Data[,c("NUMBED", "TPY")]), centers = 2)
km.sqrfoot <- kmeans(scale(na.omit(Data[,c("SQRFOOT", "TPY")])), centers = 2)
km.quant <- kmeans(scale(na.omit(Data[,c("NUMBED", "SQRFOOT", "TPY")])), centers = 2)
# Numerosità nei due cluster
table(km.numbed$cluster)
table(km.sqrfoot$cluster)
table(km.quant$cluster)
# Numerosità molto asimmetriche
```
Le tre tabelle indicano le numerosità dei due cluster rispettivamente per il raggruppamento con NUMBED, SQRFOOT e entrambe.

Visualizziamo graficamente le differenze riscontrate tra il clustering bivariato e quello con tutte e tre le variabili quantitative.
```{r, echo = F}

# Dataframe di supporto per la rappresentazione grafica
data.centers.numbed <- data.frame(NUMBED = km.numbed$centers[,1]*sd(DataNa$NUMBED)+mean(DataNa$NUMBED),
                                  TPY = km.numbed$centers[,2]*sd(DataNa$TPY)+mean(DataNa$TPY))
data.centers.sqrfoot <- data.frame(SQRFOOT = km.sqrfoot$centers[,1]*sd(na.omit(Data$SQRFOOT))+mean(na.omit(Data$SQRFOOT)),
                                  TPY = km.sqrfoot$centers[,2]*sd(Data$TPY)+mean(Data$TPY))
data.centers.numbed.qt <- data.frame(NUMBED = km.quant$centers[,1]*sd(Data$NUMBED)+mean(Data$NUMBED),
                                  TPY = km.quant$centers[,2]*sd(Data$TPY)+mean(Data$TPY))
data.centers.sqrfoot.qt <- data.frame(SQRFOOT = km.quant$centers[,1]*sd(na.omit(Data$SQRFOOT))+mean(na.omit(Data$SQRFOOT)),
                                   TPY = km.quant$centers[,2]*sd(Data$TPY)+mean(Data$TPY))
# Visualizzo graficamente i clustering
n1 <- ggplot(DataNa, aes(x = NUMBED, y = TPY, col = factor(km.numbed$cluster))) +
  geom_point(shape = 1) +
  scale_color_manual(values = c("red", "orange")) + 
  theme_bw() +
  theme(legend.position = "") +
  geom_point(data = data.centers.numbed, aes(x = NUMBED, y = TPY), col = "black") +
  labs(title = "TPY e NUMBED")
n2 <- ggplot(DataNa, aes(x = NUMBED, y = TPY, col = factor(km.quant$cluster))) +
  geom_point(shape = 1) +
  scale_color_manual(values = c("red", "orange")) + 
  theme_bw() +
  theme(legend.position = "") +
  geom_point(data = data.centers.numbed.qt, aes(x = NUMBED, y = TPY), col = "black") +
  labs(title = "TPY, NUMBED e SQRFOOT")
n3 <- ggplot(DataNa, aes(x = NUMBED, y = TPY)) +
  geom_point(data = DataNa[factor(km.quant$cluster) == factor(km.numbed$cluster),], 
             mapping = aes(x = NUMBED, y = TPY),
             shape = 1, col = "yellow") +
  geom_point(data = DataNa[factor(km.quant$cluster) != factor(km.numbed$cluster),],
             mapping = aes(x = NUMBED, y = TPY),
             shape = 1, col = "red") +
  theme_bw() +
  geom_point(data = data.centers.numbed, aes(x = NUMBED, y = TPY), col = "black") +
  geom_point(data = data.centers.numbed.qt, aes(x = NUMBED, y = TPY), col = "grey")  +
  labs(title = "Differenze tra i due clustering")
n12 <- plot_grid(n1, n2,
                 nrow = 1)
plot_grid(n12,
          n3,
          ncol = 1)
s1 <- ggplot(na.omit(Data), aes(x = SQRFOOT, y = TPY, col = factor(km.sqrfoot$cluster))) +
  geom_point(shape = 1) + 
  scale_color_manual(values = c("orange", "red")) +
  theme_bw() +
  theme(legend.position = "") +
  geom_point(data = data.centers.sqrfoot, aes(x = SQRFOOT, y = TPY), col = "black") +
  labs(title = "TPY e SQRFOOT")
s2 <- ggplot(na.omit(Data), aes(x = SQRFOOT, y = TPY, col = factor(km.quant$cluster))) +
  geom_point(shape = 1) + 
  scale_color_manual(values = c("red", "orange")) +
  theme_bw() +
  theme(legend.position = "") +
  geom_point(data = data.centers.sqrfoot, aes(x = SQRFOOT, y = TPY), col = "black") +
  labs(title = "TPY, NUMBED e SQRFOOT")
s3 <- ggplot(DataNa, aes(x = SQRFOOT, y = TPY)) +
  geom_point(data = DataNa[factor(km.quant$cluster) != factor(km.sqrfoot$cluster),], 
             mapping = aes(x = SQRFOOT, y = TPY),
             shape = 1, col = "yellow") +
  geom_point(data = DataNa[factor(km.quant$cluster) == factor(km.sqrfoot$cluster),],
             mapping = aes(x = SQRFOOT, y = TPY),
             shape = 1, col = "red") +
  theme_bw() +
  geom_point(data = data.centers.sqrfoot, aes(x = SQRFOOT, y = TPY), col = "black") +
  geom_point(data = data.centers.sqrfoot.qt, aes(x = SQRFOOT, y = TPY), col = "grey") +
  labs(title = "Differenze tra i due clustering")
s12 <- plot_grid(s1, s2,
                 nrow = 1)
plot_grid(s12,
          s3,
          ncol = 1)
```
Si osservano in rosso i punti che appartengono a due cluster diversi a seconda del tipo di clustering adottato, in grigio i centri dei cluster ottenuti utilizzando tutte e tre le variabili.
